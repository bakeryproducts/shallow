{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "from contextlib import contextmanager\n",
    "from collections.abc import Iterable\n",
    "from functools import partial, reduce\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import ToPILImage\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def poolcontext(*args, **kwargs):\n",
    "    pool = mp.Pool(*args, **kwargs)\n",
    "    yield pool\n",
    "    pool.terminate()\n",
    "    \n",
    "def mp_func(foo, args, n):\n",
    "    args_chunks = [args[i:i + n] for i in range(0, len(args), n)]\n",
    "    with poolcontext(processes=n) as pool:\n",
    "        res = pool.map(foo, args_chunks)\n",
    "    return [ri for r in res for ri in r]\n",
    "\n",
    "\n",
    "def mp_func_gen(foo, args, n, progress=None):\n",
    "    args_chunks = [args[i:i + n] for i in range(0, len(args), n)]\n",
    "    results = []\n",
    "    with poolcontext(processes=n) as pool:\n",
    "        gen = pool.imap(foo, args_chunks)\n",
    "        if progress is not None: gen = progress(gen, total=len(args_chunks))\n",
    "        for r in gen:\n",
    "            results.extend(r)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noop (x=None, *args, **kwargs): return x\n",
    "\n",
    "def noops(self, x=None, *args, **kwargs): return x\n",
    "\n",
    "def compose2(f, g):return lambda *a, **kw: f(g(*a, **kw))\n",
    "\n",
    "def compose(*fs):return reduce(compose2, fs)\n",
    "\n",
    "def tpi(i): return ToPILImage()(i)\n",
    "\n",
    "def in_docker(): return os.path.exists('/.dockerenv')\n",
    "\n",
    "def timestamp(): return '{:%Y_%b_%d_%H_%M_%S}'.format(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]\n",
    "\n",
    "def setify(o): return o if isinstance(o,set) else set(listify(o))\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "\n",
    "def store_attr(self, ll):\n",
    "    self.__dict__.update(ll)\n",
    "    del self.__dict__['self']\n",
    "\n",
    "def custom_dir(c, add:list):\n",
    "    \"Implement custom `__dir__`, adding `add` to `cls`\"\n",
    "    return dir(type(c)) + list(c.__dict__.keys()) + add\n",
    "\n",
    "class GetAttr:\n",
    "    \"Inherit from this to have all attr accesses in `self._xtra` passed down to `self.default`\"\n",
    "    _default='default'\n",
    "    def _component_attr_filter(self,k):\n",
    "        if k.startswith('__') or k in ('_xtra',self._default): return False\n",
    "        xtra = getattr(self,'_xtra',None)\n",
    "        return xtra is None or k in xtra\n",
    "    def _dir(self): return [k for k in dir(getattr(self,self._default)) if self._component_attr_filter(k)]\n",
    "    def __getattr__(self,k):\n",
    "        if self._component_attr_filter(k):\n",
    "            attr = getattr(self,self._default,None)\n",
    "            if attr is not None: return getattr(attr,k)\n",
    "        raise AttributeError(k)\n",
    "    def __dir__(self): return custom_dir(self,self._dir())\n",
    "#     def __getstate__(self): return self.__dict__\n",
    "    def __setstate__(self,data): self.__dict__.update(data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListContainer():\n",
    "    def __init__(self, items): self.items = listify(items)\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, (int,slice)): return self.items[idx]\n",
    "        if isinstance(idx[0],bool):\n",
    "            assert len(idx)==len(self) # bool mask\n",
    "            return [o for m,o in zip(idx,self.items) if m]\n",
    "        return [self.items[i] for i in idx]\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return iter(self.items)\n",
    "    def __setitem__(self, i, o): self.items[i] = o\n",
    "    def __delitem__(self, i): del(self.items[i])\n",
    "    def __repr__(self):\n",
    "        res = f'{self.__class__.__name__} ({len(self)} items)\\n{self.items[:10]}'\n",
    "        if len(self)>10: res = res[:-1]+ '...]'\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_cuda_devices(gpu_idx):\n",
    "    if os.environ.get('CUDA_VISIBLE_DEVICES') is None:\n",
    "        gpus = ','.join([str(g) for g in gpu_idx])\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = gpus\n",
    "    else:\n",
    "        print(f'WARNING, GPU OS AND CFG CONFLICT: ', cfg.TRAIN.GPUS, os.environ.get('CUDA_VISIBLE_DEVICES'))\n",
    "        print('USING ', os.environ.get('CUDA_VISIBLE_DEVICES'))\n",
    "\n",
    "class TorchBuffer:\n",
    "    # TODO convert to torch.Tensor extension\n",
    "    def __init__(self, shape=(1,), device=torch.device('cpu'), max_len=200):\n",
    "        self.shape = shape\n",
    "        self.count = 0\n",
    "        self.max_len = max_len\n",
    "        self.enlarge_factor = 2\n",
    "        self.device = device\n",
    "        self.buffer = torch.zeros((self.max_len, *self.shape)).to(self.device)\n",
    "        \n",
    "    def enlarge_buffer(self):\n",
    "        self.max_len = int(self.max_len * self.enlarge_factor)\n",
    "        #print(f'BUFFER GROWS TO {self.max_len}')\n",
    "        self.new_buffer = torch.zeros((self.max_len, *self.shape)).to(self.device)\n",
    "        self.new_buffer[:self.count] = self.buffer[:self.count]\n",
    "        self.buffer = self.new_buffer\n",
    "        \n",
    "    def push(self, t):\n",
    "        if self.count > .9 * self.max_len: self.enlarge_buffer()\n",
    "        self.buffer[self.count,...] = t\n",
    "        self.count += 1\n",
    "       \n",
    "    @property\n",
    "    def data(self): return self.buffer[:self.count]\n",
    "    def reset(self):\n",
    "        self.count=0\n",
    "        self.buffer.zero_()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_master(f):\n",
    "    def wrapper(*args):\n",
    "        if args[0].cfg.PARALLEL.IS_MASTER:\n",
    "            return f(*args)\n",
    "    return wrapper\n",
    "\n",
    "def on_epoch_step(f):\n",
    "    def wrapper(*args):\n",
    "        if (args[0].n_epoch % args[0].step) == 0:\n",
    "            return f(*args)\n",
    "    return wrapper\n",
    "\n",
    "def on_train(f):\n",
    "+   1     def wrapper(*args):\n",
    "+   2         if args[0].model.training:\n",
    "+   3             return f(*args)\n",
    "+   4     return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "ts = TorchBuffer()\n",
    "[ts.push(torch.tensor(i)) for i in range(1, 31)]\n",
    "(ts.buffer != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "ts = TorchBuffer(shape=(2,2), max_len=5)\n",
    "[ts.push(torch.ones(2,2)*i) for i in range(1, 7)]\n",
    "ts.buffer.shape, (ts.buffer != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "ts = TorchBuffer(device=torch.device('cuda:1'))\n",
    "[ts.push(torch.tensor(i)) for i in range(1, 31)]\n",
    "(ts.buffer != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataset):\n",
    "    '''Compute the mean and std value of dataset.'''\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "    print('==> Computing mean and std..')\n",
    "    for inputs, targets in dataloader:\n",
    "        for i in range(3):\n",
    "            mean[i] += inputs[:,i,:,:].mean()\n",
    "            std[i] += inputs[:,i,:,:].std()\n",
    "    mean.div_(len(dataset))\n",
    "    std.div_(len(dataset))\n",
    "    return mean, std\n",
    "\n",
    "def init_params(net):\n",
    "    '''Init layer parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal(m.weight, std=1e-3)\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "notebooks//ipynb,shallow//py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
